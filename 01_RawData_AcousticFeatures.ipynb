{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Extract rank, artist name, song name from Billboards.com #####\n",
    "import urllib.request as ur\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "url=\"http://www.billboard.com/charts/greatest-hot-100-singles\"\n",
    "data=BeautifulSoup(ur.urlopen(url), \"lxml\")\n",
    "x1=data.find('div', class_='chart-data chart-data--first-week')\n",
    "\n",
    "ranks=list()\n",
    "names=list()\n",
    "artists=list()\n",
    "for tag in x1.find_all(True):\n",
    "    if tag.name=='span':\n",
    "        ranks.append(tag.text)\n",
    "    if tag.name=='h2':\n",
    "        names.append(tag.text)\n",
    "    if tag.name=='h3':        #Some artist names are dead links, hence use 'h3' tag instead of 'a' tag\n",
    "        artists.append(tag.text)\n",
    "\n",
    "#Remove \\n and spaces in between the artist name        \n",
    "artists_r=list()\n",
    "pattern='[\\n,\\s]+(.+)[\\n,\\s]+'\n",
    "regex=re.compile(pattern)\n",
    "for artist in artists:\n",
    "    l=regex.findall(artist)\n",
    "    if l:\n",
    "        artists_r.append(l[0])   #[0] to get rid of \"[]\" around each artist name\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'ranks': ranks, 'songs': names, 'artists' : artists_r})\n",
    "collist=[\"ranks\",\"songs\",\"artists\"] #To preserve order of columns\n",
    "df.to_csv(\"/Users/Pragya/Documents/PythonProject/music/newdataset/alltimehits.csv\", columns=collist, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Cleaning of dataset extracted above to get it in format usable by Echonest API ######\n",
    "import pandas as pd\n",
    "import re\n",
    "df=pd.read_csv(\"/Users/Pragya/Documents/PythonProject/music/newdataset/alltimehits.csv\", index_col=False)\n",
    "rows=(df.shape)[0]\n",
    "\n",
    "pattern1=\"(.+)\\(.*\"\n",
    "regex1=re.compile(pattern1)\n",
    "pattern2=\"(.+)with.*\"\n",
    "regex2=re.compile(pattern2)\n",
    "pattern3=\"(.+)featuring.*\"\n",
    "regex3=re.compile(pattern3)\n",
    "pattern4=\"(.+)&.*\"\n",
    "regex4=re.compile(pattern4)\n",
    "\n",
    "for i in range(rows):\n",
    "    l1=regex1.findall(df.ix[i,1].lower())\n",
    "    l2=regex2.findall(df.ix[i,2].lower())\n",
    "    l3=regex3.findall(df.ix[i,2].lower())\n",
    "    l4=regex4.findall(df.ix[i,2].lower())\n",
    "    if l1:\n",
    "        df.ix[i,1]=l1[0]\n",
    "    if l2:\n",
    "        df.ix[i,2]=l2[0]\n",
    "    if l3:\n",
    "        df.ix[i,2]=l3[0]\n",
    "    if l4:\n",
    "        df.ix[i,2]=l4[0]\n",
    "\n",
    "collist=[\"ranks\",\"songs\",\"artists\"] #To preserve order of columns\n",
    "df.to_csv(\"/Users/Pragya/Documents/PythonProject/music/newdataset/alltimehits_cleaned.csv\", columns=collist, index=False)\n",
    "\n",
    "\n",
    "\n",
    "##### Getting song id of each song using Echonest API #####\n",
    "import urllib.request as ur\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "table=pd.read_csv(\"/Users/Pragya/Documents/PythonProject/music/newdataset/alltimehits_cleaned.csv\")\n",
    "rows=(table.shape)[0]\n",
    "table['ids']=0\n",
    "for i in range(rows): #Get links in correct format for processing (replace spaces by %20)\n",
    "    table.ix[i,1]=table.ix[i,1].replace(' ',\"%20\")\n",
    "    table.ix[i,2]=table.ix[i,2].replace(' ',\"%20\")\n",
    "\n",
    "\n",
    "for i in range(rows): \n",
    "    print(i)\n",
    "    url=\"http://developer.echonest.com/api/v4/song/search?api_key=VGJ6FVZUID01CPIRP&artist=%s&title=%s\" %(table.ix[i,2], table.ix[i,1])\n",
    "    for j in range(2): \n",
    "        try: \n",
    "            response=ur.urlopen(url)\n",
    "            break   # No need to try again since data is read (no problems)\n",
    "        except Exception as e: \n",
    "            print(\"Couldn't do it: %s\" %e)\n",
    "            if(e.msg==\"Too Many Requests\"): #Case of HTTP Error 429: Too Many Requests\n",
    "                time.sleep(61) # Sleep then try again one more time (since the j for loop runs twice unless break)\n",
    "            else: #Case of HTTP Error 400: Bad Request (e.g. song name Me & U; not for cases like artist name has word \"featuring\")\n",
    "                j=5 # Set j to a value that won't be taken during this loop (i.e. anything other than 0 and 1)\n",
    "                break  # No need to try again, since the problem won't be solved unless done manually \n",
    "    if(j==5): # Check for case of HTTP Error 400: Bad Request (the else part above)\n",
    "        continue # Go to next iteration of the i for loop\n",
    "       \n",
    "    data=response.read()\n",
    "    data=data.decode('utf-8') #Converted bytes type to string\n",
    "    data_j=json.loads(data) #Converted string type to json type\n",
    "    songs=data_j['response']['songs']\n",
    "    if songs: #For the case when name not in required format\n",
    "        table.ix[i,3]=songs[0]['id']\n",
    "\n",
    "for i in range(rows): #Get back the original names for storing (remove %20) \n",
    "    table.ix[i,1]=table.ix[i,1].replace(\"%20\", ' ')\n",
    "    table.ix[i,2]=table.ix[i,2].replace(\"%20\", ' ')\n",
    "\n",
    "\n",
    "print(table) \n",
    "collist=[\"ranks\",\"songs\",\"artists\", \"ids\"] #To preserve order of columns\n",
    "table.to_csv(\"/Users/Pragya/Documents/PythonProject/music/newdataset/alltimehits_ids.csv\", columns=collist, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### use song id to get acoustic features #####\n",
    "import urllib.request as ur\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "table=pd.read_csv(\"/Users/Pragya/Documents/PythonProject/music/newdataset/alltimehits_ids.csv\")\n",
    "rows=(table.shape)[0]\n",
    "table['acousticness']=0\n",
    "table['danceability']=0\n",
    "table['duration']=0\n",
    "table['energy']=0\n",
    "table['key']=0\n",
    "table['liveness']=0\n",
    "table['loudness']=0\n",
    "table['mode']=0\n",
    "table['speechiness']=0\n",
    "table['tempo']=0\n",
    "table['time_signature']=0\n",
    "table['valence']=0\n",
    "\n",
    "for i in range(rows):\n",
    "    url=\"http://developer.echonest.com/api/v4/song/profile?api_key=VGJ6FVZUID01CPIRP&id=%s&bucket=audio_summary\" %(table.ix[i,3])\n",
    "    print(i)\n",
    "    \n",
    "    for j in range(2):\n",
    "        try: \n",
    "            response=ur.urlopen(url)\n",
    "            break   \n",
    "        except Exception as e: \n",
    "            print(\"Couldn't do it: %s\" %e)\n",
    "            if(e.msg==\"Too Many Requests\"): \n",
    "                time.sleep(61) \n",
    "            else: \n",
    "                j=5 \n",
    "                break   \n",
    "    if(j==5): \n",
    "        continue\n",
    "\n",
    "    data=response.read()\n",
    "    data=data.decode('utf-8') #Converted bytes type to string\n",
    "    data_j=json.loads(data) #Converted string type to json type\n",
    "    song=(data_j['response']['songs'])[0]\n",
    "    if song:\n",
    "        table.ix[i,4]=song['audio_summary']['acousticness']\n",
    "        table.ix[i,5]=song['audio_summary']['danceability']\n",
    "        table.ix[i,6]=song['audio_summary']['duration']\n",
    "        table.ix[i,7]=song['audio_summary']['energy']\n",
    "        table.ix[i,8]=song['audio_summary']['key']\n",
    "        table.ix[i,9]=song['audio_summary']['liveness']\n",
    "        table.ix[i,10]=song['audio_summary']['loudness']\n",
    "        table.ix[i,11]=song['audio_summary']['mode']\n",
    "        table.ix[i,12]=song['audio_summary']['speechiness']\n",
    "        table.ix[i,13]=song['audio_summary']['tempo']\n",
    "        table.ix[i,14]=song['audio_summary']['time_signature']\n",
    "        table.ix[i,15]=song['audio_summary']['valence']\n",
    "\n",
    "table.to_csv(\"/Users/Pragya/Documents/PythonProject/music/newdataset/alltimehits_acoustics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
