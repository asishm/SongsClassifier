{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/pandas/io/data.py:35: FutureWarning: \n",
      "The pandas.io.data module is moved to a separate package (pandas-datareader) and will be removed from pandas in a future version.\n",
      "After installing the pandas-datareader package (https://github.com/pydata/pandas-datareader), you can change the import ``from pandas.io import data, wb`` to ``from pandas_datareader import data, wb``.\n",
      "  FutureWarning)\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:55: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 23)\n",
      "(909, 23)\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Created-Date: 04/14/2016                            #\n",
    "# Last Modified: 04/27/2016                           #\n",
    "# Created by: Himanshu Bharara , Shravan Kumar        #\n",
    "#                                                     #\n",
    "# Objective: Build an SVM model using a non-linear    #\n",
    "#            kernel on the original features          #\n",
    "#                                                     #\n",
    "#                                                     #\n",
    "# Instruction before running:                         #\n",
    "# 1. Please change the file path of directory         # \n",
    "# 2. change ranges based on the number of lyrics      # \n",
    "#    you have in the directory                        #  \n",
    "# 3. Please follow similar nomenclature as used in the# \n",
    "#    code                                             #\n",
    "# 4. Please use the array list of only the years      #\n",
    "#    under consideration and comment the rest         #\n",
    "# 5. Please use the scenario definition to assign 0's #\n",
    "#    to the relevant subset of the super set          #\n",
    "#######################################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.io.data\n",
    "from statsmodels import regression\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "dhome = \"/Users/HimanshuBharara/Documents/CU-Sem2/IEORE4571/Projects/Datasets/songs\"\n",
    "year = ['2006','2007','2008','2009','2010','2011','2012','2013','2014','2015']\n",
    "#year = ['2030','2020']\n",
    "## Adding 1's to 2020 Dataset\n",
    "filepath = dhome+year[0]+\".csv\"\n",
    "df=pd.read_csv(filepath)\n",
    "grades = []\n",
    "for row in df['ranks']:\n",
    "    if  row <= 20:\n",
    "        grades.append(1)\n",
    "    else:\n",
    "        grades.append(0)\n",
    "df['grades'] = grades\n",
    "\n",
    "## Adding 0's to 2030 Dataset\n",
    "#filepath = dhome+year[11]+\".csv\"\n",
    "#df1=pd.read_csv(filepath)\n",
    "#grades = []\n",
    "#for row in df1['ranks']:\n",
    "#    if  row <= 103:\n",
    "#        grades.append(0)\n",
    "#    else:\n",
    "#        grades.append(1)\n",
    "#df1['grades'] = grades\n",
    "\n",
    "#df = df.append(df1)\n",
    "\n",
    "\n",
    "## Adding 0's to Remaining Dataset\n",
    "for i in range(1,10):\n",
    "    filepath = dhome+year[i]+\".csv\"\n",
    "    mds = pd.read_csv(filepath,header=0)\n",
    "    grades = []\n",
    "    for row in mds['ranks']:\n",
    "        if  row <= 20:\n",
    "            grades.append(1)\n",
    "        else:\n",
    "            grades.append(0)\n",
    "    mds['grades'] = grades\n",
    "    df = df.append(mds)\n",
    "\n",
    "print(df.shape)\n",
    "#print(list(df.columns.values))\n",
    "\n",
    "## Drop Duplicates\n",
    "od = df.sort(['songs','artists'], ascending=[1,0])\n",
    "ot=od.drop_duplicates(['songs','artists'], keep='first')\n",
    "print(ot.shape)\n",
    "ot.pop('ranks')\n",
    "ot.pop('ids')\n",
    "ot.pop('artists')\n",
    "ot.pop('songs')\n",
    "#ot['grades'].value_counts()\n",
    "pd.DataFrame(ot.describe()).to_csv(\"/Users/HimanshuBharara/Documents/CU-Sem2/IEORE4571/Projects/SummaryStatistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681, 19)\n",
      "(228, 19)\n",
      "['acousticness', 'danceability', 'duration', 'energy', 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence', 'Anger', 'Surprise', 'Joy', 'Sadness', 'Love', 'Fear', 'grades']\n"
     ]
    }
   ],
   "source": [
    "##Using SVM WithOut PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "df_train,df_test = train_test_split(ot,random_state=1)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(list(df_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training the model based on the training dataset based on a RBF kernel\n",
    "y = df_train['grades']\n",
    "df_train.pop('grades')\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(df_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815789473684\n",
      "[511 142]\n",
      "[[  1.83577000e-01   5.20939000e-01   1.80557910e+02 ...,   1.06305765e+00\n",
      "    1.25678170e+00   1.15397713e+00]\n",
      " [  1.32100000e-03   6.17437000e-01   2.18586210e+02 ...,   1.38891021e+00\n",
      "    1.76345414e+00   1.57055388e+00]\n",
      " [  6.02560000e-02   4.85194000e-01   2.71906670e+02 ...,   1.33171974e+00\n",
      "    1.70377882e+00   1.52387684e+00]\n",
      " ..., \n",
      " [  5.25320000e-02   4.22613000e-01   2.14831020e+02 ...,   1.48145228e+00\n",
      "    1.77358261e+00   1.59541945e+00]\n",
      " [  1.10030000e-02   7.13792000e-01   2.03840000e+02 ...,   1.17810532e+00\n",
      "    1.50554902e+00   1.32188820e+00]\n",
      " [  2.29042000e-01   7.50862000e-01   2.18722810e+02 ...,   9.52505973e-01\n",
      "    1.21223215e+00   1.07645090e+00]]\n",
      "[-0.78182668]\n"
     ]
    }
   ],
   "source": [
    "## Testing the model based on the test dataset based and summarizing support vectors and analyzing modelling accuracy\n",
    "z = df_test['grades']\n",
    "df_test.pop('grades')\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(clf.predict(df_test),z))\n",
    "print(clf.n_support_)\n",
    "print(clf.support_vectors_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
