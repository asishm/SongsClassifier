{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 23)\n",
      "(909, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:54: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Created-Date: 04/11/2016                            #\n",
    "# Last Modified: 04/27/2016                           #\n",
    "# Created by: Himanshu Bharara , Shravan Kumar        #\n",
    "#                                                     #\n",
    "# Objective: build a logistic regression model        #\n",
    "#            on the training and test data for        #\n",
    "#            different scenarios mentioned in ppt     #\n",
    "#                                                     #\n",
    "# Instruction before running:                         #\n",
    "# 1. Please change the file path of directory         # \n",
    "# 2. change ranges based on the number of lyrics      # \n",
    "#    you have in the directory                        #  \n",
    "# 3. Please follow similar nomenclature as used in the# \n",
    "#    code                                             #\n",
    "# 4. Please use the array list of only the years      #\n",
    "#    under consideration and comment the rest         #\n",
    "# 5. Please use the scenario definition to assign 0's #\n",
    "#    to the relevant subset of the super set          #\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.io.data\n",
    "from statsmodels import regression\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "dhome = \"/Users/HimanshuBharara/Documents/CU-Sem2/IEORE4571/Projects/Datasets/songs\"\n",
    "year = ['2006','2007','2008','2009','2010','2011','2012','2013','2014','2015']\n",
    "#year = ['2030','2020']\n",
    "## Adding 1's to 2020 Dataset\n",
    "filepath = dhome+year[0]+\".csv\"\n",
    "df=pd.read_csv(filepath)\n",
    "grades = []\n",
    "for row in df['ranks']:\n",
    "    if  row <= 20:\n",
    "        grades.append(1)\n",
    "    else:\n",
    "        grades.append(0)\n",
    "df['grades'] = grades\n",
    "\n",
    "## Adding 0's to 2030 Dataset\n",
    "#filepath = dhome+year[11]+\".csv\"\n",
    "#df1=pd.read_csv(filepath)\n",
    "#grades = []\n",
    "#for row in df1['ranks']:\n",
    "#    if  row <= 103:\n",
    "#        grades.append(0)\n",
    "#    else:\n",
    "#        grades.append(1)\n",
    "#df1['grades'] = grades\n",
    "\n",
    "#df = df.append(df1)\n",
    "\n",
    "## Adding 0's to Remaining Dataset\n",
    "for i in range(1,10):\n",
    "    filepath = dhome+year[i]+\".csv\"\n",
    "    mds = pd.read_csv(filepath,header=0)\n",
    "    grades = []\n",
    "    for row in mds['ranks']:\n",
    "        if  row <= 20:\n",
    "            grades.append(1)\n",
    "        else:\n",
    "            grades.append(0)\n",
    "    mds['grades'] = grades\n",
    "    df = df.append(mds)\n",
    "\n",
    "print(df.shape)\n",
    "#print(list(df.columns.values))\n",
    "\n",
    "## Drop Duplicates\n",
    "od = df.sort(['songs','artists'], ascending=[1,0])\n",
    "ot=od.drop_duplicates(['songs','artists'], keep='first')\n",
    "print(ot.shape)\n",
    "ot.pop('ranks')\n",
    "ot.pop('ids')\n",
    "ot.pop('artists')\n",
    "ot.pop('songs')\n",
    "#ot['grades'].value_counts()\n",
    "## Print the summary statistics of the modelling data set to an external file to analyse before preceding for modelling\n",
    "pd.DataFrame(ot.describe()).to_csv(\"/Users/HimanshuBharara/Documents/CU-Sem2/IEORE4571/Projects/SummaryStatistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681, 19)\n",
      "(228, 19)\n",
      "0    551\n",
      "1    130\n",
      "Name: grades, dtype: int64\n",
      "0    173\n",
      "1     55\n",
      "Name: grades, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "df_train,df_test = train_test_split(ot,random_state=0)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(list(df_train.columns.values))\n",
    "print(df_train['grades'].value_counts())\n",
    "print(df_test['grades'].value_counts())\n",
    "# Print the summary statistics of the training data set to an external file to analyse before preceding for modelling\n",
    "pd.DataFrame(df_train.describe()).to_csv(\"/Users/HimanshuBharara/Documents/CU-Sem2/IEORE4571/Projects/TrainingSummaryStatistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809104258443\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression Without PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "y = df_train['grades']\n",
    "df_train.pop('grades')\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(df_train, y)  \n",
    "print(model_lr.score(df_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Predicting Logistic Regression on Testing DataSet\n",
    "z = df_test['grades']\n",
    "df_test.pop('grades')\n",
    "fit = model_lr.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.76      0.86       228\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.76      0.86       228\n",
      "\n",
      "0.758771929825\n",
      "[[173  55]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "## Summary Statistics for Classifier Algorithm\n",
    "print(metrics.classification_report(fit, z))\n",
    "print(metrics.accuracy_score(fit, z))     \n",
    "print(metrics.confusion_matrix(fit, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.500000\n"
     ]
    }
   ],
   "source": [
    "## Calculate Area under the ROC courve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(z, fit,pos_label=1) # recall my labels are 4,5 and 6\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model using cross-validation(using 10-Fold)\n",
    "md_Y = ot['grades']\n",
    "ot.pop('grades')\n",
    "md_X = ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79347826  0.79347826  0.79347826  0.79347826  0.79120879  0.8         0.8\n",
      "  0.8         0.8         0.8       ]\n",
      "0.796512183469\n"
     ]
    }
   ],
   "source": [
    "## Calculate cross validation metrics for understanding modelling accuracy\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(LogisticRegression(), md_X, md_Y, scoring='accuracy', cv=10)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
